module: "Azure Databricks"
name: "spark jvm heap usage"
filtering: "filter('resource_type', 'Microsoft.DataFactory/factories') and filter('primary_aggregation_type', 'true')"
aggregation: ".sum(by=['name'])"
transformation: ".min(over='5m')"
value_unit: "%"
signals:
  adf_activity_succeeded_run:
    metric: "ActivitySucceededRuns"
  adf_activity_failed_run:
    metric: "ActivityFailedRuns"
  signal:
    formula:
      (adf_activity_failed_run/(adf_activity_succeeded_run+adf_activity_failed_run)).scale(100).fill(0)
rules:
  critical:
    threshold: 20
    comparator: ">"
  major:
    threshold: 10
    comparator: ">"
    dependency: critical
